{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaliniAnandaPhD/Fine_Tuning/blob/main/Fine_tuning_a_BERT_Model_for_Text_Prediction_on_Perovskite_Solar_Cell_Literature.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "The following code snippet is a comprehensive demonstration of several machine learning tasks: web scraping, data preprocessing, training a language model, and making predictions with the trained model. The code is set in the context of Perovskite solar cells, a type of solar cell that is being actively researched for its potential to outperform traditional silicon cells. The aim is to fine-tune a BERT model on documents related to Perovskite to understand and predict subsequent words in new texts regarding this technology.\n",
        "\n",
        "\n",
        "# Test\n",
        "\n",
        "To test the code, we perform web scraping on both arXiv and specific education sites to gather texts related to Perovskite solar cells. These documents are combined and split into training, validation, and testing sets. This data is then used to train a BERT model with a masked language model task using PyTorch and Hugging Face's `transformers` library.\n",
        "\n",
        "In the training phase, the model learns to predict a masked word in a sentence, learning the context and semantics of the text data. Following training, the model and tokenizer are saved for later use.\n",
        "\n",
        "In the prediction phase, a sentence related to Perovskite solar cells is passed through the fine-tuned BERT model to predict subsequent words. The input text is: \"One of the advantages of perovskite solar cells over traditional silicon cells is their depth\".\n",
        "\n",
        "# Conclusion\n",
        "\n",
        "This code showcases a full cycle of a machine learning project from data gathering to prediction. By using tools like BeautifulSoup for web scraping, Hugging Face's `transformers` library for language model fine-tuning, and PyTorch for model training and inference, it demonstrates the power of these libraries in creating sophisticated NLP applications.\n",
        "\n",
        "In the field of renewable energy, such a fine-tuned model can be particularly useful for understanding the complex research language and predicting text, enabling a wide array of applications such as document summarization, question-answering, and more. Future work could explore different architectures or training strategies to further improve the model's performance."
      ],
      "metadata": {
        "id": "B8YGzE4cVfyg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xeLKfqV8FQ2"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Web scrape papers from arxiv.org using search term \"perovskite\"\n",
        "papers = []\n",
        "for i in range(1, 10):\n",
        "    url = f\"https://arxiv.org/search/?query=perovskite&start={i}\"\n",
        "    resp = requests.get(url)\n",
        "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "    for match in soup.find_all('p', class_='mathjax'):\n",
        "        papers.append(match.text)\n",
        "\n",
        "# Scrape intro texts from Wikipedia, education sites\n",
        "intros = []\n",
        "for url in [\"https://en.wikipedia.org/wiki/Perovskite_(structure)\", \"http://www.pv.unsw.edu.au/perovskite-solar-cells\"]:\n",
        "    resp = requests.get(url)\n",
        "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "    for para in soup.find_all('p'):\n",
        "        intros.append(para.text)\n",
        "\n",
        "# Combine all documents\n",
        "docs = papers + intros\n",
        "\n",
        "# Split into train, val, test sets\n",
        "random.shuffle(docs)\n",
        "n = len(docs)\n",
        "train = docs[:int(0.8*n)]\n",
        "val = docs[int(0.8*n):int(0.9*n)]\n",
        "test = docs[int(0.9*n):]\n",
        "\n",
        "# Write to text files\n",
        "with open(\"perovskite_train.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(train))\n",
        "\n",
        "with open(\"perovskite_val.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(val))\n",
        "\n",
        "with open(\"perovskite_test.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 980,
          "referenced_widgets": [
            "d56af6243e6f45fc8fd435c7da3a4150",
            "cb68add878054e1badb94451281479c0",
            "750b3ed005ef4bd6b1a7e3609d01ebb5",
            "dba89e22370c45b2b7969ec6192d9a21",
            "e90f7322fde64417ab2a8b20a6616e7f",
            "db2188acca2b4d5994b1892a792f4f46",
            "39d682610b234873bdd11c5a047a5569",
            "2d70a19530b7481292c032e4f9b7dac0",
            "6b79fcd5b28d4b4aafbeca265f1e6c38",
            "bfdf925e318749b8bfc01e52ceb15c54",
            "0286a25486874d0b96aa8caabe105825"
          ]
        },
        "id": "KwRjlwdoFqou",
        "outputId": "bb8f092f-0154-48ab-b498-b61975137d12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d56af6243e6f45fc8fd435c7da3a4150",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/64 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('perovskite_bert_tokenizer/tokenizer_config.json',\n",
              " 'perovskite_bert_tokenizer/special_tokens_map.json',\n",
              " 'perovskite_bert_tokenizer/vocab.txt',\n",
              " 'perovskite_bert_tokenizer/added_tokens.json',\n",
              " 'perovskite_bert_tokenizer/tokenizer.json')"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "\n",
        "# Imports\n",
        "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
        "from datasets import load_dataset, Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW\n",
        "\n",
        "import torch\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# Load dataset\n",
        "try:\n",
        "    with open('/content/perovskite_train.txt', 'r') as file:\n",
        "        data = file.readlines()\n",
        "    dataset = Dataset.from_dict({'text': data})\n",
        "except FileNotFoundError:\n",
        "    print(\"The file was not found at the specified location.\")\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])\n",
        "\n",
        "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
        "\n",
        "# Prepare data loader\n",
        "train_dataloader = DataLoader(tokenized_dataset, shuffle=True, batch_size=8)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Training loop\n",
        "model.train()\n",
        "\n",
        "gradient_accumulation_steps = 4\n",
        "num_train_epochs = 5\n",
        "\n",
        "for epoch in range(num_train_epochs):\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        inputs, attention_mask = batch['input_ids'].to(device), batch['attention_mask'].to(device)\n",
        "        outputs = model(inputs, attention_mask=attention_mask, labels=inputs)\n",
        "        loss = outputs.loss\n",
        "        loss = loss / gradient_accumulation_steps  # Normalize the loss because it is accumulated over multiple batches\n",
        "        loss.backward()\n",
        "\n",
        "        if (step + 1) % gradient_accumulation_steps == 0 or step == len(train_dataloader) - 1:  # Perform the optimization step if we've accumulated enough gradients or it's the last batch\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "# Save model and tokenizer\n",
        "model.save_pretrained(\"perovskite_bert_model\")\n",
        "tokenizer.save_pretrained(\"perovskite_bert_tokenizer\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "import torch\n",
        "\n",
        "# Load the saved tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"perovskite_bert_tokenizer\")\n",
        "\n",
        "# Load the saved model\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"perovskite_bert_model\")\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "# Some new text data for prediction\n",
        "text = \"One of the advantages of perovskite solar cells over traditional silicon cells is their depth\"\n",
        "\n",
        "# Encode the text\n",
        "encoded_input = tokenizer(text, return_tensors='pt')\n",
        "\n",
        "# Move the encoded input to the same device as the model\n",
        "encoded_input = encoded_input.to(device)\n",
        "\n",
        "# Make prediction\n",
        "with torch.no_grad():\n",
        "    output = model(**encoded_input)\n",
        "\n",
        "# Get the predicted token ids\n",
        "predicted_token_ids = torch.argmax(output.logits, dim=-1)\n",
        "\n",
        "# Decode the token ids to tokens\n",
        "predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_token_ids[0])\n",
        "\n",
        "print(predicted_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1RX1_8KO_LS",
        "outputId": "6c5c0d6b-1778-4c13-91b3-f2eed084acc1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'one', 'of', 'the', 'advantages', 'of', 'per', '##ov', '##ski', '##te', 'solar', 'cells', 'over', 'traditional', 'silicon', 'cells', 'is', 'their', 'depth', '.']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNGbpvX9oM+ba3/hrXrBslz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0286a25486874d0b96aa8caabe105825": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d70a19530b7481292c032e4f9b7dac0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39d682610b234873bdd11c5a047a5569": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b79fcd5b28d4b4aafbeca265f1e6c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "750b3ed005ef4bd6b1a7e3609d01ebb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d70a19530b7481292c032e4f9b7dac0",
            "max": 64,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b79fcd5b28d4b4aafbeca265f1e6c38",
            "value": 64
          }
        },
        "bfdf925e318749b8bfc01e52ceb15c54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb68add878054e1badb94451281479c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db2188acca2b4d5994b1892a792f4f46",
            "placeholder": "​",
            "style": "IPY_MODEL_39d682610b234873bdd11c5a047a5569",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "d56af6243e6f45fc8fd435c7da3a4150": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb68add878054e1badb94451281479c0",
              "IPY_MODEL_750b3ed005ef4bd6b1a7e3609d01ebb5",
              "IPY_MODEL_dba89e22370c45b2b7969ec6192d9a21"
            ],
            "layout": "IPY_MODEL_e90f7322fde64417ab2a8b20a6616e7f"
          }
        },
        "db2188acca2b4d5994b1892a792f4f46": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dba89e22370c45b2b7969ec6192d9a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfdf925e318749b8bfc01e52ceb15c54",
            "placeholder": "​",
            "style": "IPY_MODEL_0286a25486874d0b96aa8caabe105825",
            "value": " 64/64 [00:00&lt;00:00, 61.76 examples/s]"
          }
        },
        "e90f7322fde64417ab2a8b20a6616e7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}